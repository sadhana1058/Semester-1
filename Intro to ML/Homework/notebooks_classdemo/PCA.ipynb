{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.io import loadmat\n",
    "import mpld3\n",
    "from mpld3 import plugins\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A toy example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First generate some data\n",
    "mu = np.array([0,0])\n",
    "Sigma = np.array([[ 46.28249177,  26.12496001],\n",
    "       [ 26.12496001,  19.55457642]])\n",
    "X = np.random.multivariate_normal(mu,Sigma,1000)\n",
    "fig = plt.figure(figsize=[8,8])\n",
    "plt.scatter(X[:,0],X[:,1])\n",
    "plt.xlabel('x', fontsize=12)\n",
    "plt.ylabel('y', fontsize=12)\n",
    "plt.grid(axis='both')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform PCA\n",
    "L,U=np.linalg.eig(Sigma)\n",
    "# eigenvalues\n",
    "print(L)\n",
    "# eigenvectors\n",
    "print(U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first plot the eigenvectors\n",
    "ah=0.1 # size of arrow head\n",
    "f=1.1 # axes range\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.subplot(111,aspect='equal')\n",
    "plt.arrow(0,0,U[0,0],U[1,0],color='r',linewidth=2,head_width=ah,head_length=ah)\n",
    "plt.arrow(0,0,U[0,1],U[1,1],color='r',linewidth=2,head_width=ah,head_length=ah)\n",
    "plt.text(f*U[0,0],f*U[1,0],r'Eigenvector 1, $\\vec{v_1}$ =  %.2f $\\vec{x}$ + %.2f $\\vec{y}$' % (U[0,0],U[1,0]), fontsize=15)\n",
    "plt.text(f*U[0,1],f*U[1,1],r'Eigenvector 2, $\\vec{v_1}$ =  %.2f $\\vec{x}$ + %.2f $\\vec{y}$' % (U[0,1],U[1,1]), fontsize=15)\n",
    "plt.xlim([-f,f])\n",
    "plt.ylim([-f,f])\n",
    "plt.xlabel('x',fontsize=15)\n",
    "plt.ylabel('y',fontsize=15)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the eigenvectors with the data\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.plot(X[:,0],X[:,1],'bo',markersize=5,zorder=1,)\n",
    "plt.axis('equal')\n",
    "plt.grid()\n",
    "plt.title('Principal Components (eigenvectors) of random data', fontsize=12)\n",
    "plt.xlabel('x', fontsize=12)\n",
    "plt.ylabel('y', fontsize=12)\n",
    "\n",
    "plt.arrow(0,0,U[0,0]*math.sqrt(L[0]),U[1,0]*math.sqrt(L[0]),color='r',linewidth=2,head_width=1,head_length=1)\n",
    "plt.arrow(0,0,U[0,1]*math.sqrt(L[1]),U[1,1]*math.sqrt(L[1]),color='r',linewidth=2,head_width=1,head_length=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# projecting data onto the principal components (no dimensionality reduction here)\n",
    "Z = np.dot(X,U)\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.axis('equal')\n",
    "plt.grid()\n",
    "plt.plot(Z[:,0],Z[:,1],'bo',markersize=5)\n",
    "plt.xlabel('Principal Component 1',fontsize=15)\n",
    "plt.ylabel('Principal Component 2',fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# projecting data onto the first principal component\n",
    "Z = np.dot(X,U[:,1])\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.axis('equal')\n",
    "plt.grid()\n",
    "plt.plot(Z,np.zeros([len(Z),]),'bo',markersize=5)\n",
    "plt.xlabel('Principal Component 1',fontsize=15)\n",
    "#plt.ylabel('Principal Component 2',fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playing with digit data using PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will study the impact of PCA on a data belonging to the same class (or digit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = loadmat('mnist_sample.mat') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load digit 3 data\n",
    "digit3data = mat.get('train3')\n",
    "digit3data = np.array(digit3data,dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit3data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display a sample image\n",
    "plt.imshow(np.reshape(digit3data[0,:],((28,28))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform PCA\n",
    "L = 100\n",
    "X = scale(digit3data)\n",
    "pca = PCA(n_components=L)\n",
    "pca.fit(X)\n",
    "# first visualize the explained variance\n",
    "W = pca.components_\n",
    "plt.plot(pca.explained_variance_ratio_)\n",
    "# largest eigen values\n",
    "print(pca.explained_variance_)\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(np.sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us use only the first L principal components to represent one row\n",
    "# We are reducing the dimensionality from 784 to L!!!\n",
    "Z = pca.transform(X)\n",
    "# Recover data in original space using the reduced data\n",
    "Xhat = np.dot(Z,W)\n",
    "fig = plt.figure(figsize=[10,8])\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(np.reshape(X[0,:],((28,28))))\n",
    "plt.title('Original Image')\n",
    "plt.subplot(1,3,2)\n",
    "plt.title('Recovered Image')\n",
    "plt.imshow(np.reshape(Xhat[0,:],((28,28))))\n",
    "ax = plt.subplot(1,3,3)\n",
    "plt.title('Difference')\n",
    "im = plt.imshow(np.reshape(Xhat[0,:]-X[0,:],((28,28))))\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "\n",
    "plt.colorbar(im, cax=cax)\n",
    "#plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will see how PCA allows us to embed data into 2D (or arbitrary low dimensional) space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load all data\n",
    "alltraindata = mat.get('train0')\n",
    "labels = np.zeros([alltraindata.shape[0],1])\n",
    "for i in range(1,10):\n",
    "    m = mat.get('train'+str(i))\n",
    "    alltraindata = np.vstack((alltraindata,m))\n",
    "    labels = np.vstack((labels,i*np.ones([m.shape[0],1])))\n",
    "alltraindata = np.array(alltraindata,dtype=float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scale(alltraindata)\n",
    "L = X.shape[1]\n",
    "pca = PCA(n_components=L)\n",
    "pca.fit(X)\n",
    "# first visualize the explained variance\n",
    "W = pca.components_\n",
    "plt.plot(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform PCA using 3 dimensions\n",
    "L = 3\n",
    "X = scale(alltraindata)\n",
    "pca = PCA(n_components=L)\n",
    "pca.fit(X)\n",
    "Z = pca.transform(X)\n",
    "fig = plt.figure(figsize=[12,12])\n",
    "ax = fig.gca(projection='3d')\n",
    "for i in range(10):\n",
    "    inds = np.where(labels == i)[0]\n",
    "    ax.scatter(Z[inds,0],Z[inds,1],Z[inds,2],c='C%d'%i,label='%d'%i)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform PCA using 2 dimensions\n",
    "L = 2\n",
    "X = scale(alltraindata)\n",
    "pca = PCA(n_components=L)\n",
    "pca.fit(X)\n",
    "Z = pca.transform(X)\n",
    "# plot a sample of data in embedded 2D space\n",
    "fig = plt.figure(figsize=[12,12])\n",
    "scatter = plt.scatter(Z[:,0],Z[:,1],c=labels)\n",
    "labels1 = ['%d'%(labels[i]) for i in range(Z.shape[0])]\n",
    "tooltip = mpld3.plugins.PointLabelTooltip(scatter, labels=labels1)\n",
    "mpld3.plugins.connect(fig, tooltip)\n",
    "mpld3.display(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction using PCA - Eigen Faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_grid(D,H,W,cols=10,scale=1):\n",
    "    \"\"\" display a grid of images\n",
    "        H,W: Height and width of the images\n",
    "        cols: number of columns = number of images in each row\n",
    "        scale: 1 to fill screen\n",
    "    \"\"\"\n",
    "    n = np.shape(D)[0]\n",
    "    rows = int(math.ceil((n+0.0)/cols))\n",
    "    fig = plt.figure(1,figsize=[scale*20.0/H*W,scale*20.0/cols*rows],dpi=300)\n",
    "    for i in range(n):\n",
    "        plt.subplot(rows,cols,i+1)\n",
    "        fig=plt.imshow(np.reshape(D[i,:],[H,W]), cmap = plt.get_cmap(\"gray\"))\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read face images \n",
    "extensions = ['centerlight', 'glasses', 'happy', 'leftlight', 'noglasses', 'normal', 'rightlight', 'sad', 'sleepy', 'surprised', 'wink' ]\n",
    "basename = 'data/yalefaces/subject'\n",
    "numimages = 15*len(extensions)\n",
    "# read one image to get dimensions\n",
    "m = Image.open(basename+'01.centerlight').convert(\"L\")\n",
    "r,c = np.shape(m)\n",
    "X = np.zeros([numimages,r*c])\n",
    "cnt = 0\n",
    "for i in range(1,16):\n",
    "    basename1 = basename+str(i).zfill(2)\n",
    "    for ex in extensions:\n",
    "        fullname = basename1+'.'+ex\n",
    "        m = Image.open(fullname).convert(\"L\")\n",
    "        X[cnt,:] = np.reshape(np.asarray(m),[1,r*c])\n",
    "        cnt = cnt + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display raw data using the image_grid function\n",
    "image_grid(X,r,c,cols=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a training and test sample\n",
    "s = np.random.permutation(numimages)\n",
    "trainX = X[s[0:100],:]\n",
    "testX = X[s[100:],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the mean face\n",
    "meanTrainFace = np.mean(trainX,axis=0)\n",
    "fig=plt.imshow(np.reshape(meanTrainFace,[r,c]), cmap = plt.get_cmap(\"gray\"))\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# center data \n",
    "trainXcentered = trainX - meanTrainFace\n",
    "\n",
    "# plot the random 10 centered faces\n",
    "image_grid(trainXcentered[:10,:],r,c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainXcentered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform PCA\n",
    "pca = PCA()\n",
    "p = pca.fit(trainXcentered)\n",
    "# first visualize the explained variance\n",
    "W = p.components_\n",
    "plt.plot(p.explained_variance_ratio_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above plot is also known as a **scree plot**. Typically, the number of principal components chosen ($L$) for dimensionality reduction is obtained by observing the scree plot and identifying the \"knee\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the top L eigenfaces\n",
    "L = 100\n",
    "image_grid(W[0:L,:],r,c,cols=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a sample test image (unseen)\n",
    "x = testX[7:8,:]\n",
    "xcentered = x - meanTrainFace\n",
    " \n",
    "image_grid(x,r,c,cols=4)\n",
    "plt.show()\n",
    "image_grid(xcentered,r,c,cols=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reconstruct the test image using top $L$ principal components. \n",
    "Xhat = np.zeros([L,xcentered.shape[1]])\n",
    "for i in range(L):\n",
    "    z = np.dot(W[0:i+1,:],xcentered.transpose())\n",
    "    Xhat[i,:] = np.dot(z.transpose(),W[0:i+1,:])\n",
    "\n",
    "image_grid(Xhat,r,c,cols=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
