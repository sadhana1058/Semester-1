# CSE 475: Machine Learning  
**Instructor:** Mingchen Gao  
**When:** Tuesday, 2-4 PM  
**Where:** Davis 317

---

## Course Description

Machine learning is the study of algorithms that enable computers to learn from experience and make predictions or decisions without explicit programming. This course introduces the fundamental algorithms and techniques in machine learning, such as classification, clustering, and recommendation systems. You'll gain hands-on experience in applying machine learning methods to real-world problems, while also learning the theory behind them.

### Topics Covered:
- **Generative Models**
- **Bayesian Learning**
- **Linear & Logistic Regression**
- **Perceptron & Neural Networks**
  - **Convolutional Neural Networks (CNN)**
  - **Recurrent Neural Networks (RNN)**
- **Reinforcement Learning**
- **Graphical Models**
- **Clustering & Latent Linear Models**
- **Support Vector Machines**
- **Decision Trees, Boosting, Random Forests**
- **Hidden Markov Models**

This course combines both theoretical foundations and practical applications, providing the knowledge to apply machine learning in various domains such as spam filtering, fraud detection, and natural language understanding.

---

## General Information

### Prerequisites:
- CSE 250, and either EAS 305/308, STA 401/421, MTH 309; or permission of instructor.

### Course Website:  
[https://piazza.com/buffalo/fall2024/cse475574/home](https://piazza.com/buffalo/fall2024/cse475574/home)  
All course announcements, materials, and communications will be available on this website. Ensure you check it regularly.

---

## Textbook

- **Primary Textbook:**  
  Kevin Murphy, *Probabilistic Machine Learning: An Introduction*, MIT Press, 2022.  
  [Book Website](https://probml.github.io/pml-book/book1.html)

- **Optional Recommended Reading:**  
  - Chris Bishop, *Pattern Recognition and Machine Learning*, Springer, 2006.
  - Tom Mitchell, *Machine Learning*, McGraw-Hill, 1997.
  - David Mackay, *Information Theory, Inference, and Learning Algorithms*, Cambridge Press, 2003.
  - Trevor Hastie, Robert Tibshirani, Jerome Friedman, *The Elements of Statistical Learning*, Springer, 2009.
  - Richard Duda, Peter Hart, David Stork, *Pattern Classification*, 2nd ed. John Wiley & Sons, 2001.

---

## Grading Information

The course grade will be calculated as follows:
- **In-class Questions**: 10%
- **Weekly Quizzes (12 total)**: 20%
- **Programming Assignments (3)**: 30%
- **Mid-term Exam 1** (Open book/notes, Oct 1, 2024): 10%
- **Mid-term Exam 2** (Open book/notes, Nov 5, 2024): 10%
- **Final Exam** (Open book/notes, Dec 16, 2024): 20%

### Grading Notes:
- Late submissions are penalized after the allowance of five late days for programming assignments (25% penalty per day beyond five days).
- **No make-up exams** will be allowed for the final, except under university-approved reasons.
  
### Letter Grades:  
Letter grades will be assigned in the range of A to F, with possible minuses and pluses.

---

## Python Setup

### Install Python and Dependencies:
- **Python, IPython Installation Guide**: [http://ipython.org/install.html](http://ipython.org/install.html)
- **Python IDE (Enthought)**: [https://store.enthought.com/downloads/#default](https://store.enthought.com/downloads/#default)
- **Jupyter Notebooks Guide**: [http://ipython.org/notebook.html](http://ipython.org/notebook.html)

### Recommended Reading:
- **"Introduction to Machine Learning with Python"** by Andreas Mueller and Sarah Guido  
  [GitHub Repo](https://github.com/amueller/introduction_to_ml_with_python)

- **"Python for Developers"** by Ricardo Duarte:  
  [Book Website](http://ricardoduarte.github.io/python-for-developers/)

---

## Important Dates
- **Mid-term Exam 1**: Oct 1, 2024 (Tuesday)
- **Mid-term Exam 2**: Nov 5, 2024 (Tuesday)
- **Final Exam**: Dec 16, 2024

---

